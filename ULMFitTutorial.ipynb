{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/linsut/masterarbeit/blob/master/ULMFitTutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 880
    },
    "colab_type": "code",
    "id": "h4MhFcvJ1b3v",
    "outputId": "b69f9a85-cac7-4b6e-b53b-88c8fb0c9d9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/nightly/cu92/torch_nightly.html\n",
      "Collecting torch_nightly\n",
      "\u001b[?25l  Downloading https://download.pytorch.org/whl/nightly/cu92/torch_nightly-1.2.0.dev20190805%2Bcu92-cp36-cp36m-linux_x86_64.whl (704.8MB)\n",
      "\u001b[K     |████████████████████████████████| 704.8MB 25kB/s \n",
      "\u001b[?25hInstalling collected packages: torch-nightly\n",
      "Successfully installed torch-nightly-1.2.0.dev20190805+cu92\n",
      "Requirement already satisfied: fastai in /usr/local/lib/python3.6/dist-packages (1.0.60)\n",
      "Requirement already satisfied: nvidia-ml-py3 in /usr/local/lib/python3.6/dist-packages (from fastai) (7.352.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from fastai) (3.2.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from fastai) (2.21.0)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from fastai) (0.5.0)\n",
      "Requirement already satisfied: bottleneck in /usr/local/lib/python3.6/dist-packages (from fastai) (1.3.2)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from fastai) (4.6.3)\n",
      "Requirement already satisfied: numexpr in /usr/local/lib/python3.6/dist-packages (from fastai) (2.7.1)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from fastai) (3.13)\n",
      "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from fastai) (1.18.2)\n",
      "Requirement already satisfied: fastprogress>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from fastai) (0.2.2)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from fastai) (0.25.3)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from fastai) (7.0.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from fastai) (1.4.1)\n",
      "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from fastai) (1.4.0)\n",
      "Requirement already satisfied: spacy>=2.0.18 in /usr/local/lib/python3.6/dist-packages (from fastai) (2.2.4)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from fastai) (0.7)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from fastai) (20.3)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (2.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (1.1.0)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (2019.11.28)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (3.0.4)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision->fastai) (1.12.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->fastai) (2018.9)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (0.4.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (2.0.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (4.38.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (0.6.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (3.0.2)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (1.1.3)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (1.0.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (46.0.0)\n",
      "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (7.4.0)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (1.0.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai) (1.0.2)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.0.18->fastai) (1.5.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.0.18->fastai) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch_nightly -f https://download.pytorch.org/whl/nightly/cu92/torch_nightly.html\n",
    "!pip install fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n_CJa_yj2DtZ"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import fastai\n",
    "from fastai import *\n",
    "from fastai.text import * \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "import io\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "Au-_cr562H6L",
    "outputId": "a7415984-dfd9-4a9f-8ae7-f4f678051cf2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 20news dataset. This may take a few minutes.\n",
      "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "dataset = fetch_20newsgroups(shuffle=True, random_state=1, remove=('headers', 'footers', 'quotes'))\n",
    "documents = dataset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pdy94Ws12P8K"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'label':dataset.target, 'text':dataset.data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "rOiGJ4lX2hWK",
    "outputId": "98d485ac-2ff6-4231-c5b0-afcbf4154e6a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6UDiQLQC3PRl"
   },
   "outputs": [],
   "source": [
    "df = df[df['label'].isin([1,10])]\n",
    "df = df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "qGTuSZbQ3_1E",
    "outputId": "7ce40ab6-d802-48db-e707-7684dba6db38"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10    600\n",
       "1     584\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "edFe7Tra4DLk"
   },
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.replace(\"[^a-zA-Z]\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "rBMz84775-o1",
    "outputId": "cd470be6-0c28-4f1d-bf98-e4898aa5a976"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Lina\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords \n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9-a0f69ALc4Z"
   },
   "outputs": [],
   "source": [
    "# tokenization \n",
    "tokenized_doc = df['text'].apply(lambda x: x.split())\n",
    "\n",
    "# remove stop-words \n",
    "tokenized_doc = tokenized_doc.apply(lambda x: [item for item in x if item not in stop_words])\n",
    "\n",
    "# de-tokenization \n",
    "detokenized_doc = [] \n",
    "for i in range(len(df)): \n",
    "    t = ' '.join(tokenized_doc[i]) \n",
    "    detokenized_doc.append(t) \n",
    "\n",
    "df['text'] = detokenized_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c1JYwrHjLhsl"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data into training and validation set\n",
    "df_trn, df_val = train_test_split(df, stratify = df['label'], test_size = 0.4, random_state = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "pLA4miE4Llo3",
    "outputId": "5398afb6-309a-4a4e-a359-438d952b4c53"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((710, 2), (474, 2))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trn.shape, df_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "colab_type": "code",
    "id": "vuPRwXTSLoEs",
    "outputId": "332e58a6-4a0a-44cf-eadb-be387f31e4a6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Language model data\n",
    "data_lm = TextLMDataBunch.from_df(train_df = df_trn, valid_df = df_val, path = \"\")\n",
    "\n",
    "# Classifier model data\n",
    "data_clas = TextClasDataBunch.from_df(path = \"\", train_df = df_trn, valid_df = df_val, vocab=data_lm.train_ds.vocab, bs=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "5iBIJum-LsW1",
    "outputId": "eb219e46-806a-4469-fee5-c80e0a022d8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://s3.amazonaws.com/fast-ai-modelzoo/wt103-fwd\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = language_model_learner(data_lm, drop_mult=0.7, arch = AWD_LSTM, pretrained = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "colab_type": "code",
    "id": "Njcj37p9LwS-",
    "outputId": "fa239a2d-4680-406a-e908-187b6468ddd9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.104345</td>\n",
       "      <td>5.197469</td>\n",
       "      <td>0.249027</td>\n",
       "      <td>01:43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train the learner object with learning rate = 1e-2\n",
    "learn.fit_one_cycle(1, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0WYJ5Lq8M02w"
   },
   "outputs": [],
   "source": [
    "learn.save_encoder('ft_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "0AamTl5UM9op",
    "outputId": "cbeb771b-0ca6-43d3-c7d3-1548902adee3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNLearner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList (710 items)\n",
       "x: TextList\n",
       "xxbos xxmaj it looks like xxmaj edmonton xxmaj oilers decided take xxmaj european xxunk spring xxmaj ranford xxmaj tugnutt xxmaj benning xxmaj manson xxmaj smith xxmaj buchberger xxmaj corson playing xxmaj canada xxmaj podein xxmaj weight playing xxup us xxmaj is xxmaj kravchuk playing xxmaj xxunk i know nagging injuries late season xxmaj podein interesting case eligible play xxmaj cape xxmaj breton xxup ahl playoffs like xxmaj kovalev xxmaj zubov xxmaj andersson obviously xxmaj sather xxmaj pocklington total xxunk everyone makes certainly case massively xxunk xxmaj paramount xxmaj new xxmaj york xxmaj rangers,xxbos xxmaj this xxunk xxmaj speaking die hard i i read xxunk hard xxunk xxmaj toronto xxmaj cup finals xxmaj first anyone planet heard team xxmaj detroit xxmaj al xxmaj xxunk however spell idiot name must xxmaj chicago xxup espn said even close xxmaj chicago xxunk win xxmaj norris xxmaj division xxmaj playoffs team close xxmaj everyone picking xxmaj chicago i get says easy choice xxmaj god xxmaj chicago xxmaj wings division point two followed closely xxmaj toronto also good team xxmaj as xxmaj leafs beating xxmaj detroit doubt even going get xxmaj chicago xxmaj if even xxunk get past xxmaj hawks would probably face xxmaj vancouver lose xxmaj as xxmaj the xxmaj habs reaching xxmaj finals forget xxmaj even i devoted xxmaj wings fan watch xxmaj penguins easily three xxunk xxmaj cup winners xxmaj lemieux xxmaj jagr xxmaj tocchet xxmaj stevens xxmaj barrasso done deal xxmaj sorry xxmaj detroit wait xxunk next year xxmaj but hey xxmaj paul picks everyone right xxunk xxmaj leafs xxmaj finals xxmaj yeah xxmaj if make i walk xxmaj toronto get tickets mile walk xxmaj ryan,xxbos xxmaj the idea clip one polygon using another polygon necessarily rectangular window xxmaj my problem finding new vertices resulting xxunk first one xxmaj is simply matter extending usual algorithm whereby edges one polygon checked another polygon xxmaj is simpler way xxmaj comments welcome,xxbos i xxmaj edmonton usually least xxup often case xxunk actual xxup abc xxunk xxmaj kings xxmaj flames game i whoever said earlier xxmaj don xxmaj xxunk er xxmaj whitman poor commentator hockey xxmaj normally xxmaj oilers still playing xxunk i would turn sound listen radio broadcast get decent play play announcing,xxbos xxmaj you know absolutely right i think round players xxmaj european xxunk ship em back came xxmaj let see start i dunno xxmaj lemieux xxmaj hmmm sounds like xxmaj french blood xxmaj hey xxmaj france part xxmaj europe xxmaj send xxmaj xxunk xxunk boy back xxmaj sheesh i think would hard find xxmaj native xxmaj americans xxmaj native xxmaj canadians matter would xxunk claim great continent xxmaj ya see believe xxunk xxunk sort xxmaj if really think xxmaj mogilny xxmaj bure xxmaj selanne et al improved xxup nhl i sure understand game\n",
       "y: CategoryList\n",
       "10,10,1,10,10\n",
       "Path: .;\n",
       "\n",
       "Valid: LabelList (474 items)\n",
       "x: TextList\n",
       "xxbos i looking source code radiosity method i know kind machine want program xxmaj radiance comes c source code i ftp access i tell get via way,xxbos i interested information xxunk imaging sun workstation xxmaj for part i need know hardware available interface system whether xxunk rates sufficient produce quality image xxunk xxmaj any information subject would greatly appreciated,xxbos xxmaj does anyone xxup nhl xxup standings xxmaj march th i need xxup xxunk project xxmaj please post email xxup thanks,xxbos a little xxunk xxmaj basic xxmaj mike info xxmaj for xxmaj xxunk xxunk xxup abc announcing xxunk xxmaj devils xxmaj isles xxmaj pittsburgh xxmaj gary xxmaj thorne play play xxmaj bill xxmaj clement color xxmaj al xxmaj xxunk xxunk xxunk outside xxunk xxunk xxmaj this xxunk primarily seen xxmaj east xxmaj coast xxmaj st xxmaj louis xxmaj chicago xxmaj mike xxmaj xxunk play play xxmaj jim xxmaj xxunk color xxmaj tom xxmaj xxunk xxunk xxunk xxmaj this xxunk primarily seen xxmaj midwest parts xxmaj south xxup la xxmaj calgary xxmaj al xxmaj do xxmaj you xxmaj believe xxmaj xxunk xxmaj michaels play play xxmaj john xxmaj davidson color xxmaj mark xxmaj jones xxunk reporter xxmaj this xxunk seen xxmaj western xxup usa xxmaj montreal xxunk xxmaj xxunk xxmaj xxunk xxunk studio xxup abc xxmaj up xxmaj close xxmaj personal xxmaj mario xxmaj saturday xxmaj wide xxmaj world xxmaj sports xxup edt xxmaj sunday first xxup nhl playoff regular network xxunk years counting silly xxmaj all xxmaj star games xxup xxunk last years xxmaj for xxmaj sunday games xxup abc use xxunk behind goal super super xxunk xxunk close xxunk player faces face xxunk xxup espn xxup abc able use new favorite xxunk ice level shot xxmaj pittsburgh many seats would removed xxunk xxmaj in case blowout xxunk xxmaj pittsburgh xxup abc switch xxmaj chicago game come back xxmaj pittsburgh game updates game gets closer xxmaj xxunk xxup abc xxunk huge ratings hockey standards since xxmaj top xxup us xxup tv markets involved xxup ny xxunk area xxup ny xxmaj islanders xxup nj xxmaj devils xxmaj chicago blackhawks xxup la xxmaj kings xxmaj stay tuned xxmaj thanks xxmaj mike,xxbos xxmaj world xxmaj championships xxmaj germany xxmaj group a results xxup sweden xxup canada st nd xxup can xxmaj geoff xxmaj sanderson xxmaj kevin xxmaj dineen xxup xxunk xxmaj patrik xxmaj xxunk xxmaj jan xxmaj xxunk pp rd xxup can xxmaj geoff xxmaj sanderson ps xxup can xxmaj mike xxmaj gartner xxmaj greg xxmaj xxunk xxmaj adam xxmaj graves xxup can xxmaj rod xxmaj brind xxmaj amour xxmaj shayne xxmaj corson xxmaj shots goal xxmaj penalties xxmaj attendance xxmaj referee xxmaj sweden min xxmaj rob xxmaj xxunk xxup usa xxmaj canada min xxmaj bill xxmaj ranford stopped shots lead xxmaj canada victory well played game xxmaj the first period started give away xxmaj canadian defenseman xxmaj xxunk came alone xxmaj ranford put puck xxunk xxmaj ranford xxmaj later xxmaj kevin xxmaj dineen great opportunity xxmaj soderstrom played well xxmaj xxunk xxmaj nilsson couple great xxunk set xxmaj jan xxmaj xxunk xxmaj ranford came big xxmaj period ended xxunk edge xxmaj sweden creating opportunities xxmaj second period action saw xxmaj tommy xxmaj soderstrom making xxup great save xxmaj mark xxmaj recchi made xxunk cross ice pass xxmaj lindros xxmaj eric one xxunk puck xxmaj soderstrom make glove hand save xxmaj at minute mark xxmaj canada started applying pressure xxmaj xxunk xxmaj sanderson xxmaj dineen xxmaj brind xxmaj amour worked hard kept puck xxmaj xxunk zone xxmaj dineen gave puck xxmaj sanderson skated around xxunk xxmaj swedish defenseman came xxmaj soderstrom made wrist shot went xxmaj soderstrom far post xxmaj canada xxmaj the xxmaj xxunk picked game xxmaj peter xxmaj xxunk shot hit xxmaj ranford post inside went parallel goal line xxmaj then xxmaj gartner got penalty xxmaj xxunk power play xxmaj jan xxmaj xxunk took shot slot xxmaj ranford gave rebound xxmaj xxunk saw xxmaj xxunk far post passed puck xxmaj ranford beat xxmaj third period started periods xxmaj xxunk pressure xxmaj canadians always xxunk close xxmaj xxunk goal xxmaj at xxmaj canada created great chances xxmaj xxunk xxmaj xxunk forced cover puck xxmaj xxunk goal crease since xxmaj soderstrom lost sight xxmaj that xxunk penalty shot since defenseman cover puck goal crease xxmaj geoff xxmaj sanderson took penalty shot first ever explained xxunk put low xxmaj soderstrom stick side close post xxmaj excellent penalty shot give xxmaj canada go ahead goal xxmaj canada increased lead suspect xxunk xxmaj gartner xxunk bouncing puck past xxmaj soderstrom make xxmaj the xxmaj xxunk xxunk gas produce good scoring chances periods xxmaj the goal came second left xxmaj rod xxmaj brind xxmaj amour scoring rebound xxmaj soderstrom xxmaj swedish defense already xxunk xxunk room a good game best xxup wc far goalies playing great xxmaj soderstrom best player xxmaj sweden xxmaj ranford even played better xxmaj soderstrom tells something xxmaj ranford xxmaj probably best goalie world comments game xxmaj canada played disciplined defense xxmaj ranford pointed easy play well good defense xxmaj lindros played a xxup lot played well xxmaj sanderson xxunk game xxunk two goals xxmaj the xxmaj xxunk xxmaj naslund xxmaj xxunk line xxmaj sweden best along xxmaj xxunk xxmaj xxunk xxmaj nilsson xxmaj swedish defense played well xxunk xxunk xxmaj peter xxmaj xxunk task xxunk xxunk xxunk xxmaj eric xxmaj lindros managed well xxmaj ranger defenseman xxmaj peter xxmaj andersson finally got go xxup wc considering xxunk xxmaj germany hours game played well xxmaj swedish coach xxmaj xxunk xxmaj xxunk xxunk game xxunk xxmaj xxunk xxunk score xxunk linesman mistake goal xxmaj lines information follows xxup italy xxup switzerland st nd xxup xxunk xxmaj xxunk rd xxmaj penalties xxup xxunk min xxup xxunk min xxmaj referee xxmaj xxunk xxmaj xxunk xxmaj slovakia xxmaj attendance xxmaj group b results xxup czech xxup republic xxup germany st nd xxup xxunk xxmaj xxunk xxmaj xxunk xxup xxunk xxmaj jiri xxmaj xxunk xxup xxunk xxmaj petr xxmaj xxunk rd xxup xxunk xxmaj xxunk xxmaj xxunk xxup xxunk xxmaj josef xxmaj beranek xxmaj penalties xxup xxunk min xxup xxunk min min min game penalty xxmaj referee xxmaj xxunk xxmaj xxunk xxmaj canada xxmaj attendance xxmaj the xxmaj xxunk clearly better xxmaj xxunk xxmaj german crowd showed xxunk throwing stuff ice xxup finland xxup usa st nd xxup xxunk xxmaj xxunk xxmaj xxunk rd xxup usa xxmaj ed xxmaj olczyk xxmaj penalties xxup xxunk min xxup usa min xxmaj referee xxmaj xxunk xxmaj xxunk xxmaj russia xxmaj attendance i hope xxmaj xxunk provide information game i see whole game xxmaj the xxmaj xxunk took lead xxmaj xxunk xxmaj xxunk slap shot blue line soft goal xxunk xxmaj mike xxmaj richter xxmaj as far play second period goes xxmaj xxunk seemed control lead warranted i saw xxup sweden xxup canada xxmaj goaltender xxmaj tommy xxmaj soderstrom xxmaj bill xxmaj ranford xxmaj defense xxmaj kenneth xxmaj xxunk xxmaj norm xxmaj maciver xxmaj fredrik xxmaj stillman xxmaj dave xxmaj manson xxmaj peter xxmaj xxunk xxmaj geoff xxmaj smith xxmaj peter xxmaj andersson xxmaj brian xxmaj benning xxmaj xxunk xxmaj xxunk xxmaj terry xxmaj carkner xxmaj roger xxmaj xxunk xxmaj garry xxmaj galley xxmaj derek xxmaj xxunk xxmaj forwards xxmaj mikael xxmaj xxunk xxmaj dave xxmaj gagner xxmaj thomas xxmaj xxunk xxmaj adam xxmaj graves xxmaj mikael xxmaj andersson xxmaj mike xxmaj gartner xxmaj markus xxmaj naslund xxmaj paul xxmaj kariya xxmaj peter xxmaj xxunk xxmaj eric xxmaj lindros xxmaj jonas xxmaj xxunk xxmaj mark xxmaj recchi xxmaj patrik xxmaj xxunk xxmaj rod xxmaj brind xxmaj amour xxmaj jan xxmaj xxunk xxmaj shayne xxmaj corson xxmaj xxunk xxmaj nilsson xxmaj kevin xxmaj dineen xxmaj xxunk xxmaj xxunk xxmaj geoff xxmaj sanderson xxmaj michael xxmaj nylander xxmaj greg xxmaj xxunk xxmaj andersson xxmaj xxunk xxmaj brian xxmaj savage xxmaj kelly xxmaj buchberger\n",
       "y: CategoryList\n",
       "1,1,10,10,10\n",
       "Path: .;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): MultiBatchEncoder(\n",
       "    (module): AWD_LSTM(\n",
       "      (encoder): Embedding(6600, 400, padding_idx=1)\n",
       "      (encoder_dp): EmbeddingDropout(\n",
       "        (emb): Embedding(6600, 400, padding_idx=1)\n",
       "      )\n",
       "      (rnns): ModuleList(\n",
       "        (0): WeightDropout(\n",
       "          (module): LSTM(400, 1152, batch_first=True)\n",
       "        )\n",
       "        (1): WeightDropout(\n",
       "          (module): LSTM(1152, 1152, batch_first=True)\n",
       "        )\n",
       "        (2): WeightDropout(\n",
       "          (module): LSTM(1152, 400, batch_first=True)\n",
       "        )\n",
       "      )\n",
       "      (input_dp): RNNDropout()\n",
       "      (hidden_dps): ModuleList(\n",
       "        (0): RNNDropout()\n",
       "        (1): RNNDropout()\n",
       "        (2): RNNDropout()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.27999999999999997, inplace=False)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x000002503A4B40D8>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=WindowsPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
       "learn: ...\n",
       "alpha: 2.0\n",
       "beta: 1.0], layer_groups=[Sequential(\n",
       "  (0): Embedding(6600, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(6600, 400, padding_idx=1)\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.27999999999999997, inplace=False)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")], add_time=True, silent=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn = text_classifier_learner(data_clas, drop_mult=0.7, arch = AWD_LSTM)\n",
    "learn.load_encoder('ft_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "colab_type": "code",
    "id": "543wJhLdNItM",
    "outputId": "131cf770-5e12-4184-f108-ed6b05ef823d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.389399</td>\n",
       "      <td>0.216476</td>\n",
       "      <td>0.926160</td>\n",
       "      <td>03:55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "colab_type": "code",
    "id": "Ylu-SDQcNbos",
    "outputId": "332ae68c-2a16-492f-a3de-98a30c3d76db"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>220</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0    0    1\n",
       "row_0          \n",
       "0      220   21\n",
       "1       14  219"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get predictions\n",
    "preds, targets = learn.get_preds()\n",
    "\n",
    "predictions = np.argmax(preds, axis = 1)\n",
    "pd.crosstab(predictions, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fUXWhILsNikV"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPHOcm+IANcVo3MAkq92gga",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
